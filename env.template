# The embedding model to use.
#
# This is a string of the form `<kind>[:<model>]` with the following options:
#
# 1. `local:<path>` -- A local model from the given path.
# 2. `hf:<repository>` -- A hugging face model from the given repository.
# 3. `ollama:<name>` -- The named Ollama model. `OLLAMA_BASE_URL` must be set.
#
# In each of these cases, you can omit the second part for the default model of the
# given kind.
#
# If unset, this will default to `"openai"` if an OpenAI API KEY is available and
# otherwise will use `"local"`.
#
# NOTE: Changing embedding models is not currently supported.
EMBEDDING_MODEL="local"

# The LLM model to use.
#
# This is a string of the form `<kind>:<model>` with the following options:
#
# 1. `local:<path or repository>` -- Run a model locally. If this is a path
#     it will attempt to load a model from that location. Otherwise, it should
#     be a Hugging Face repository from which to retrieve the model.
# 2. `openai:<name>` -- The named OpenAI model. `OPENAI_API_KEY` must be set.
# 3. `ollama:<name>` -- The named Ollama model. `OLLAMA_BASE_URL` must be set.
#
# In each of these cases, you can omit the second part for the default model of the
# given kind.
#
# If unset, this will default to `"openai"` if an OpenAI API KEY is available and
# otherwise will use `"local"`.
#
LLM_MODEL="local"

# The OpenAI API Key to use for OpenAI models.
#
# This is required for using openai models.
#
# OPENAI_API_KEY="<your key here>"

# The Base URL for Ollama.
#
# This is required for using ollama models.
#
# OLLAMA_BASE_URL="<host>:11434"